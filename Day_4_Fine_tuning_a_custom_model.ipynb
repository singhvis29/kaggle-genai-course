{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Day 4 - Fine tuning a custom model",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "380cb0b76fc4485486258161e59db194": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_91ab3bd23611455288afea3eb2f472db",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16 \u001b[0m [ \u001b[33m0:00:05\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m3 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">16/16 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:05</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">3 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "91ab3bd23611455288afea3eb2f472db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb74809972ee4c01b1f87e24e5bcf545": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2ba65669016a4f829d6e09ae17a95e38",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32/32 \u001b[0m [ \u001b[33m0:01:07\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m1 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">32/32 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:07</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">1 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "2ba65669016a4f829d6e09ae17a95e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhvis29/kaggle-genai-course/blob/main/Day_4_Fine_tuning_a_custom_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2025 Google LLC."
      ],
      "metadata": {
        "id": "b6e13eef3f5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "cellView": "form",
        "id": "d6597b11df14",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-28T07:39:24.010656Z",
          "iopub.execute_input": "2025-02-28T07:39:24.011577Z",
          "iopub.status.idle": "2025-02-28T07:39:24.035703Z",
          "shell.execute_reply.started": "2025-02-28T07:39:24.011515Z",
          "shell.execute_reply": "2025-02-28T07:39:24.034263Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 4 - Fine tuning a custom model\n",
        "\n",
        "Welcome back to the Kaggle 5-day Generative AI course!\n",
        "\n",
        "In this notebook you will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n",
        "\n",
        "This codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files.\n",
        "\n",
        "**Note**: We recommend doing this codelab first today. There may be a period of waiting while the model tunes, so if you start with this one, you can try the other codelab while you wait."
      ],
      "metadata": {
        "id": "4KDIFPAL2EnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n",
        "!pip install -U -q \"google-genai==1.7.0\""
      ],
      "metadata": {
        "id": "9wafTyEH1_xF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:48:50.513748Z",
          "iopub.execute_input": "2025-04-02T07:48:50.51413Z",
          "iopub.status.idle": "2025-04-02T07:49:10.461862Z",
          "shell.execute_reply.started": "2025-04-02T07:48:50.514097Z",
          "shell.execute_reply": "2025-04-02T07:49:10.46006Z"
        },
        "outputId": "bb3cf403-89d1-4ef5-db38-b11c151848a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "genai.__version__"
      ],
      "metadata": {
        "id": "T0CBG9xL2PvT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:10.464654Z",
          "iopub.execute_input": "2025-04-02T07:49:10.465052Z",
          "iopub.status.idle": "2025-04-02T07:49:11.954087Z",
          "shell.execute_reply.started": "2025-04-02T07:49:10.465012Z",
          "shell.execute_reply": "2025-04-02T07:49:11.95277Z"
        },
        "outputId": "a01b929e-3415-4b89-e70c-3c2302e769cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.7.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
        "\n",
        "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
        "\n",
        "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
      ],
      "metadata": {
        "id": "P4bYX2T72ScK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "# GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "VuJPY3GK2SLZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:11.955554Z",
          "iopub.execute_input": "2025-04-02T07:49:11.956072Z",
          "iopub.status.idle": "2025-04-02T07:49:12.223295Z",
          "shell.execute_reply.started": "2025-04-02T07:49:11.956035Z",
          "shell.execute_reply": "2025-04-02T07:49:12.22195Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n",
        "\n",
        "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
      ],
      "metadata": {
        "id": "25b2127c2052"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore available models\n",
        "\n",
        "You will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create your custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."
      ],
      "metadata": {
        "id": "CqVA5QFO6n4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "    if \"createTunedModel\" in model.supported_actions:\n",
        "        print(model.name)"
      ],
      "metadata": {
        "id": "coEacWAB6o0G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:12.225628Z",
          "iopub.execute_input": "2025-04-02T07:49:12.225986Z",
          "iopub.status.idle": "2025-04-02T07:49:12.475683Z",
          "shell.execute_reply.started": "2025-04-02T07:49:12.225951Z",
          "shell.execute_reply": "2025-04-02T07:49:12.47424Z"
        },
        "outputId": "0996a0ce-5725-4cc6-832e-48130d7ba458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.5-flash-001-tuning\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset\n",
        "\n",
        "In this activity, you will use the same newsgroups dataset that [you used to train a classifier in Keras](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras/). In this example you will use a fine-tuned Gemini model to achieve the same goal.\n",
        "\n",
        "The [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets."
      ],
      "metadata": {
        "id": "peFm0w_0c1CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
        "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
        "\n",
        "# View list of class names for dataset\n",
        "newsgroups_train.target_names"
      ],
      "metadata": {
        "id": "bX_kpgnQ9b-Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:12.476866Z",
          "iopub.execute_input": "2025-04-02T07:49:12.477215Z",
          "iopub.status.idle": "2025-04-02T07:49:24.294123Z",
          "shell.execute_reply.started": "2025-04-02T07:49:12.477128Z",
          "shell.execute_reply": "2025-04-02T07:49:24.292962Z"
        },
        "outputId": "47611c31-ff39-4913-a6a2-703bfac7966b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what a single row looks like."
      ],
      "metadata": {
        "id": "ipafe6ptZFjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(newsgroups_train.data[0])"
      ],
      "metadata": {
        "id": "EtEXcdT39hCB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:24.295557Z",
          "iopub.execute_input": "2025-04-02T07:49:24.295965Z",
          "iopub.status.idle": "2025-04-02T07:49:24.301543Z",
          "shell.execute_reply.started": "2025-04-02T07:49:24.295933Z",
          "shell.execute_reply": "2025-04-02T07:49:24.300488Z"
        },
        "outputId": "99f769c2-79ae-40f3-a185-b5f9f6006afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "You'll use the same pre-processing code you used for the custom model on day 2. This pre-processing removes personal information, which can be used to \"shortcut\" to known users of a forum, and formats the text to appear a bit more like regular text and less like a newsgroup post (e.g. by removing the mail headers). This normalisation allows the model to generalise to regular text and not over-depend on specific fields. If your input data is always going to be newsgroup posts, it may be helpful to leave this structure in place if they provide genuine signals."
      ],
      "metadata": {
        "id": "03lDs1O4ZQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import email\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def preprocess_newsgroup_row(data):\n",
        "    # Extract only the subject and body\n",
        "    msg = email.message_from_string(data)\n",
        "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
        "    # Strip any remaining email addresses\n",
        "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
        "    # Truncate the text to fit within the input limits\n",
        "    text = text[:40000]\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_newsgroup_data(newsgroup_dataset):\n",
        "    # Put data points into dataframe\n",
        "    df = pd.DataFrame(\n",
        "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
        "    )\n",
        "    # Clean up the text\n",
        "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
        "    # Match label to target name index\n",
        "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "IoNYTxpoZgB0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:24.302711Z",
          "iopub.execute_input": "2025-04-02T07:49:24.303116Z",
          "iopub.status.idle": "2025-04-02T07:49:24.673312Z",
          "shell.execute_reply.started": "2025-04-02T07:49:24.30307Z",
          "shell.execute_reply": "2025-04-02T07:49:24.671991Z"
        }
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to training and test datasets\n",
        "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
        "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "kvOsUSRWaW4g",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:43.572509Z",
          "iopub.execute_input": "2025-04-02T07:49:43.573622Z",
          "iopub.status.idle": "2025-04-02T07:49:47.447228Z",
          "shell.execute_reply.started": "2025-04-02T07:49:43.573563Z",
          "shell.execute_reply": "2025-04-02T07:49:47.445992Z"
        },
        "outputId": "cad1c1c4-1aa7-4eca-d91c-dbc8df8f7532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Label  \\\n",
              "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
              "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
              "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
              "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
              "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
              "\n",
              "              Class Name  \n",
              "0              rec.autos  \n",
              "1  comp.sys.mac.hardware  \n",
              "2  comp.sys.mac.hardware  \n",
              "3          comp.graphics  \n",
              "4              sci.space  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a45d681-a637-484e-ba0c-8d24ae1ef162\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a45d681-a637-484e-ba0c-8d24ae1ef162')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a45d681-a637-484e-ba0c-8d24ae1ef162 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a45d681-a637-484e-ba0c-8d24ae1ef162');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6abd5eb6-eb47-435c-8764-092c478ed2c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6abd5eb6-eb47-435c-8764-092c478ed2c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6abd5eb6-eb47-435c-8764-092c478ed2c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 11314,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11308,\n        \"samples\": [\n          \"Re: History question\\n\\nIn article <>  (Paul Johnson) writes:\\n>\\n>I recall reading of a phonograph which used mechanical amplification.\\n>Compressed air was squirted out of a valve which was controlled by the\\n>pickup.  The result was noisy and distinctly lo-fi, but much louder\\n>than a conventional phonograph.  It tended to wear the disks out\\n>pretty quickly though.\\n\\nThis was the Pathe you are thinking of, although there were other imitators.\\nIt didn't wear the disks any more than conventional acoustic designs, but\\nit did have a high noise level due to the continual hiss of escaping air.\\nThere are a lot of them still operating, and they are pretty ingenious.\\n\\nThere was a pneumatic amplifier designed by Alexander Graham Bell, as well,\\nbut I don't know if it was ever constructed.\\n--scott\\n\",\n          \"Emulator pods\\n\\nA surplus-dealing buddy of mine came up with two emulator pods:\\n\\n\\tHP64220C (for HP 64100 development station). 8086 target\\n\\tprocessor. DIP head. Does not include board that plugs into\\n\\tthe 64100.\\n\\n\\tApplied Microsystems 80C186/188 pod, LCC head.\\n\\nIf you have an interest in either, let me know. They look to\\nbe in excellent condition. He doesn't know what to do with them, which\\nmay mean that they'll be cheap.\\n\\n-- \\n--------------------------------------------------------------------\\n       Dave Medin\\t\\t\\tPhone:\\t(205) 730-3169 (w)\\n    SSD--Networking\\t\\t\\t\\t(205) 837-1174 (h)\\n    Intergraph Corp.\\n       M/S GD3004 \\t\\tInternet: \\n  Huntsville, AL 35894\\t\\tUUCP:  ...uunet!ingr!b30!catbyte!dtmedin\\n\\n   ******* Everywhere You Look (at least around my office) *******\\n\\n * The opinions expressed here are mine (or those of my machine)\\n\",\n          \"Re: VGA 640x400 graphics mode\\n\\n writes in article <>:\\n> \\n> Greetings!\\n> \\n> Does anybody know if it is possible to set VGA graphics mode to 640x400\\n> instead of 640x480?  Any info is appreciated!\\n\\nSome VESA bios's support this mode (0x100).  And *any* VGA should be able to\\nsupport this (640x480 by 256 colors) since it only requires 256,000 bytes.\\nMy 8514/a VESA TSR supports this; it's the only VESA mode by card can support\\ndue to 8514/a restrictions. (A WD/Paradise)\\n\\n--\\nI am not responsible for anything I do or say -- I'm just an opinion.\\n             Robert J.C. Kyanko ()\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          7,\n          17,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"rec.autos\",\n          \"talk.politics.mideast\",\n          \"rec.sport.baseball\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now sample the data. You will keep 50 rows for each category for training. Note that this is even fewer than the Keras example, as this technique (parameter-efficient fine-tuning, or PEFT) updates a relatively small number of parameters and does not require training a new model or updating the large model."
      ],
      "metadata": {
        "id": "XSKcj5WtadaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_data(df, num_samples, classes_to_keep):\n",
        "    # Sample rows, selecting num_samples of each Label.\n",
        "    df = (\n",
        "        df.groupby(\"Label\")[df.columns]\n",
        "        .apply(lambda x: x.sample(num_samples))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
        "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "TRAIN_NUM_SAMPLES = 50\n",
        "TEST_NUM_SAMPLES = 10\n",
        "# Keep rec.* and sci.*\n",
        "CLASSES_TO_KEEP = \"^rec|^sci\"\n",
        "\n",
        "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
        "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
      ],
      "metadata": {
        "id": "0t9Xu6X5akkt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:47.44871Z",
          "iopub.execute_input": "2025-04-02T07:49:47.448998Z",
          "iopub.status.idle": "2025-04-02T07:49:47.504263Z",
          "shell.execute_reply.started": "2025-04-02T07:49:47.448972Z",
          "shell.execute_reply": "2025-04-02T07:49:47.502994Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate baseline performance\n",
        "\n",
        "Before you start tuning a model, it's good practice to perform an evaluation on the available models to ensure you can measure how much the tuning helps.\n",
        "\n",
        "First identify a single sample row to use for visual inspection."
      ],
      "metadata": {
        "id": "9iijp8d3yDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_idx = 0\n",
        "sample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\n",
        "sample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n",
        "\n",
        "print(sample_row)\n",
        "print('---')\n",
        "print('Label:', sample_label)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:52.104893Z",
          "iopub.execute_input": "2025-04-02T07:49:52.105294Z",
          "iopub.status.idle": "2025-04-02T07:49:52.112083Z",
          "shell.execute_reply.started": "2025-04-02T07:49:52.105259Z",
          "shell.execute_reply": "2025-04-02T07:49:52.110865Z"
        },
        "id": "u8jak-mIyDX3",
        "outputId": "d6421329-2924-4b26-8852-4d164f8a5792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need info on 88-89 Bonneville\n",
            "\n",
            "\n",
            " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "\n",
            "\t\t\tNeil Gandler\n",
            "\n",
            "---\n",
            "Label: rec.autos\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing the text directly in as a prompt does not yield the desired results. The model will attempt to respond to the message."
      ],
      "metadata": {
        "id": "t6JU5cJzyDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-1.5-flash-001\", contents=sample_row)\n",
        "print(response.text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:49:54.456192Z",
          "iopub.execute_input": "2025-04-02T07:49:54.457192Z",
          "iopub.status.idle": "2025-04-02T07:49:58.006099Z",
          "shell.execute_reply.started": "2025-04-02T07:49:54.457136Z",
          "shell.execute_reply": "2025-04-02T07:49:58.005024Z"
        },
        "id": "Zp3smxYlyDX3",
        "outputId": "c5c610b0-3b7a-4796-c7d5-8a38d541cc6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##  1988-1989 Pontiac Bonneville: A Breakdown of the Models and Value\n",
            "\n",
            "You're right, the 1988-1989 Pontiac Bonneville lineup can be a bit confusing with all the different trims. Here's a breakdown:\n",
            "\n",
            "**1. LE (Luxury Edition):**\n",
            "* **Features:** The base model, featuring standard features like cloth upholstery, air conditioning, power steering, and power brakes.\n",
            "* **Performance:** Equipped with the 3.8L V6 engine, producing around 140 horsepower.\n",
            "\n",
            "**2. SE (Special Edition):**\n",
            "* **Features:** Added features like upgraded cloth upholstery, woodgrain accents, and a rear window defroster. \n",
            "* **Performance:** Same 3.8L V6 engine as the LE.\n",
            "\n",
            "**3. LSE (Luxury Special Edition):**\n",
            "* **Features:** Combined the luxury features of the LE with the special edition touches of the SE. \n",
            "* **Performance:** Same 3.8L V6 engine.\n",
            "\n",
            "**4. SSE (Sport Special Edition):**\n",
            "* **Features:** More sporty styling with unique bodywork and wheels. Included a standard sunroof, sport suspension, and upgraded interior. \n",
            "* **Performance:** Upgraded with a 3.8L V6 with 170 horsepower or a 5.0L V8 with 210 horsepower.\n",
            "\n",
            "**5. SSEi (Sport Special Edition, Injected):**\n",
            "* **Features:**  Identical to the SSE in terms of styling and features. \n",
            "* **Performance:** Equipped with the 3.8L V6 with 165 horsepower (a slightly detuned version of the SSE V6), but offered better fuel economy. \n",
            "\n",
            "**Book Value and Prices:**\n",
            "\n",
            "* **Book Value:** The book value of a 1989 Pontiac Bonneville will depend on the model, condition, mileage, and overall desirability. Sites like Kelley Blue Book (KBB) or Edmunds can give you a good estimate. \n",
            "* **Expected Price:**  The actual price you'll pay will be lower than book value. This is typical for older cars, and you could potentially negotiate a price 20-40% below book value, especially if the vehicle needs some work.\n",
            "\n",
            "**Best Time to Buy:**\n",
            "\n",
            "You're right, **mid-spring to early summer** is generally considered the best time to buy used cars. This is because:\n",
            "\n",
            "* **Dealerships are looking to move inventory:** They want to make room for newer models.\n",
            "* **Increased competition:**  More people are looking to buy cars during this time, leading to more competitive pricing. \n",
            "\n",
            "**Important Note:** \n",
            "* **Inspect Thoroughly:**  Regardless of the season, it's crucial to have any potential purchase inspected by a trusted mechanic. This will help you avoid costly surprises later on.\n",
            "\n",
            "**Additional Considerations:**\n",
            "\n",
            "* **Rarity:** Certain models, especially the SSE and SSEi with the V8, are considered more desirable and may command a higher price.\n",
            "* **Condition:**  Well-maintained Bonnevilles, even older ones, can still be reliable and enjoyable to drive.\n",
            "\n",
            "I hope this information helps you in your search for a 1988-1989 Pontiac Bonneville! \n",
            "\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the prompt engineering techniques you have learned this week to induce the model to perform the desired task. Try some of your own ideas and see what is effective, or check out the following cells for different approaches. Note that they have different levels of effectiveness!"
      ],
      "metadata": {
        "id": "Joea8BMTyDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model directly in a zero-shot prompt.\n",
        "\n",
        "prompt = \"From what newsgroup does the following message originate?\"\n",
        "baseline_response = client.models.generate_content(\n",
        "    model=\"gemini-1.5-flash-001\",\n",
        "    contents=[prompt, sample_row])\n",
        "print(baseline_response.text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:50:05.256079Z",
          "iopub.execute_input": "2025-04-02T07:50:05.256628Z",
          "iopub.status.idle": "2025-04-02T07:50:06.077581Z",
          "shell.execute_reply.started": "2025-04-02T07:50:05.256575Z",
          "shell.execute_reply": "2025-04-02T07:50:06.075933Z"
        },
        "id": "TNGH1nC8yDX3",
        "outputId": "48ae6d66-77ca-4443-974b-147f95672669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This message likely originates from a newsgroup dedicated to **Buick cars**, specifically the **Bonneville model**.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Content:** The message focuses entirely on Buick Bonneville models from 1988-1989, discussing different trim levels and their features, performance, and market value.\n",
            "* **Terminology:** The message uses terms like \"LE,\" \"SE,\" \"LSE,\" \"SSE,\" and \"SSEi,\" which are specific trim levels associated with the Buick Bonneville during those years.\n",
            "* **Common Practice:** Newsgroups often cater to specific car models and brands, providing a platform for enthusiasts to share information and discuss related topics. \n",
            "\n",
            "Therefore, the most likely newsgroups this message originates from are:\n",
            "\n",
            "* **alt.autos.buick:** A general newsgroup for Buick car enthusiasts.\n",
            "* **rec.autos.buick:**  A newsgroup specifically for Buick car enthusiasts, likely to have discussions about the Bonneville.\n",
            "* **alt.autos.buick.bonneville:**  A newsgroup dedicated to the Buick Bonneville model. \n",
            "\n",
            "While the exact newsgroup is unclear, it's highly likely that the message originated from one of these related to Buick or specifically the Bonneville. \n",
            "\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique still produces quite a verbose response. You could try and parse out the relevant text, or refine the prompt even further."
      ],
      "metadata": {
        "id": "b8w5CLODyDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import retry\n",
        "\n",
        "# You can use a system instruction to do more direct prompting, and get a\n",
        "# more succinct answer.\n",
        "\n",
        "system_instruct = \"\"\"\n",
        "You are a classification service. You will be passed input that represents\n",
        "a newsgroup post and you must respond with the newsgroup from which the post\n",
        "originates.\n",
        "\"\"\"\n",
        "\n",
        "# Define a helper to retry when per-minute quota is reached.\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "# If you want to evaluate your own technique, replace this body of this function\n",
        "# with your model, prompt and other code and return the predicted answer.\n",
        "@retry.Retry(predicate=is_retriable)\n",
        "def predict_label(post: str) -> str:\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-1.5-flash-001\",\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_instruct),\n",
        "        contents=post)\n",
        "\n",
        "    rc = response.candidates[0]\n",
        "\n",
        "    # Any errors, filters, recitation, etc we can mark as a general error\n",
        "    if rc.finish_reason.name != \"STOP\":\n",
        "        return \"(error)\"\n",
        "    else:\n",
        "        # Clean up the response.\n",
        "        return response.text.strip()\n",
        "\n",
        "\n",
        "prediction = predict_label(sample_row)\n",
        "\n",
        "print(prediction)\n",
        "print()\n",
        "print(\"Correct!\" if prediction == sample_label else \"Incorrect.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:50:19.474289Z",
          "iopub.execute_input": "2025-04-02T07:50:19.474737Z",
          "iopub.status.idle": "2025-04-02T07:50:20.185012Z",
          "shell.execute_reply.started": "2025-04-02T07:50:19.474696Z",
          "shell.execute_reply": "2025-04-02T07:50:20.183642Z"
        },
        "id": "DwCdZ78DyDX3",
        "outputId": "3fa80a11-852b-4190-88c3-e679da2eaa83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rec.autos.misc\n",
            "\n",
            "Incorrect.\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run a short evaluation using the function defined above. The test set is further sampled to ensure the experiment runs smoothly on the API's free tier. In practice you would evaluate over the whole set."
      ],
      "metadata": {
        "id": "0BAIPY4LyDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from tqdm.rich import tqdm as tqdmr\n",
        "import warnings\n",
        "\n",
        "# Enable tqdm features on Pandas.\n",
        "tqdmr.pandas()\n",
        "\n",
        "# But suppress the experimental warning\n",
        "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
        "\n",
        "\n",
        "# Further sample the test data to be mindful of the free-tier quota.\n",
        "df_baseline_eval = sample_data(df_test, 2, '.*')\n",
        "\n",
        "# Make predictions using the sampled data.\n",
        "df_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n",
        "\n",
        "# And calculate the accuracy.\n",
        "accuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:50:36.20491Z",
          "iopub.execute_input": "2025-04-02T07:50:36.205338Z",
          "iopub.status.idle": "2025-04-02T07:51:06.125368Z",
          "shell.execute_reply.started": "2025-04-02T07:50:36.205304Z",
          "shell.execute_reply": "2025-04-02T07:51:06.124235Z"
        },
        "id": "qK9dJHpJyDX4",
        "outputId": "35b12520-3e20-4f35-8468-5f0ffd980be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "380cb0b76fc4485486258161e59db194",
            "91ab3bd23611455288afea3eb2f472db"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "380cb0b76fc4485486258161e59db194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 18.75%\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now take a look at the dataframe to compare the predictions with the labels."
      ],
      "metadata": {
        "id": "RWdHGqqDyDX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_baseline_eval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:51:06.13034Z",
          "iopub.execute_input": "2025-04-02T07:51:06.130826Z",
          "iopub.status.idle": "2025-04-02T07:51:06.144977Z",
          "shell.execute_reply.started": "2025-04-02T07:51:06.130772Z",
          "shell.execute_reply": "2025-04-02T07:51:06.143833Z"
        },
        "id": "jridDtgUyDX4",
        "outputId": "97c64173-3340-46f4-f4fc-6ac78a0129b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Text  Label  \\\n",
              "0   Re: Changing brake fluid..is it necessary..\\n\\...      7   \n",
              "1   Re: Dirty Diesels?\\n\\n  writes:\\n> I heard the...      7   \n",
              "2   Re: Countersteering sans Hands\\n\\nIn article <...      8   \n",
              "3   Re: Its still cold, but...\\n\\nIn article <>  (...      8   \n",
              "4   Phils winning the hard way\\n\\n\\nThe Phillies h...      9   \n",
              "5   Re: USA McWeekly Stats\\n <>\\n <>\\n\\nIn article...      9   \n",
              "6   Re: Another travesty at the Joe Louis\\n\\nIn ar...     10   \n",
              "7   AHL Leafs Back Home?\\n\\nApparently, the public...     10   \n",
              "8   Re: Clipper considered harmful\\n\\nIn article <...     11   \n",
              "9   Re: The [secret] source of that announcement\\n...     11   \n",
              "10  Re: How to the disks copy protected.\\n\\nIn art...     12   \n",
              "11  Re: How to the disks copy protected.\\n\\n (-xiv...     12   \n",
              "12  Re: Can men get yeast infections?\\n\\nMy (then)...     13   \n",
              "13  Re: INFO: Colonics and Purification?\\n\\nIn art...     13   \n",
              "14  Re: Space Marketing would be wonderfull.\\n\\n>>...     14   \n",
              "15  Re: HST Servicing Mission Scheduled for 11 Day...     14   \n",
              "\n",
              "            Class Name                Prediction  \n",
              "0            rec.autos          rec.autos.toyota  \n",
              "1            rec.autos          rec.autos.makers  \n",
              "2      rec.motorcycles           rec.motorcycles  \n",
              "3      rec.motorcycles        talk.politics.misc  \n",
              "4   rec.sport.baseball  rec.sports.baseball.misc  \n",
              "5   rec.sport.baseball       rec.sports.baseball  \n",
              "6     rec.sport.hockey         rec.sports.hockey  \n",
              "7     rec.sport.hockey          rec.sport.hockey  \n",
              "8            sci.crypt                   (error)  \n",
              "9            sci.crypt                   (error)  \n",
              "10     sci.electronics                   (error)  \n",
              "11     sci.electronics   comp.os.ms-windows.misc  \n",
              "12             sci.med                   (error)  \n",
              "13             sci.med                alt.health  \n",
              "14           sci.space         sci.astro.amateur  \n",
              "15           sci.space                 sci.space  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-756ec0d1-6b95-43bf-975b-81060f630a85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Re: Changing brake fluid..is it necessary..\\n\\...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "      <td>rec.autos.toyota</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Re: Dirty Diesels?\\n\\n  writes:\\n&gt; I heard the...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "      <td>rec.autos.makers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Re: Countersteering sans Hands\\n\\nIn article &lt;...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Re: Its still cold, but...\\n\\nIn article &lt;&gt;  (...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Phils winning the hard way\\n\\n\\nThe Phillies h...</td>\n",
              "      <td>9</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>rec.sports.baseball.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re: USA McWeekly Stats\\n &lt;&gt;\\n &lt;&gt;\\n\\nIn article...</td>\n",
              "      <td>9</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>rec.sports.baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Re: Another travesty at the Joe Louis\\n\\nIn ar...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>rec.sports.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AHL Leafs Back Home?\\n\\nApparently, the public...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Re: Clipper considered harmful\\n\\nIn article &lt;...</td>\n",
              "      <td>11</td>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>(error)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Re: The [secret] source of that announcement\\n...</td>\n",
              "      <td>11</td>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>(error)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Re: How to the disks copy protected.\\n\\nIn art...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "      <td>(error)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Re: How to the disks copy protected.\\n\\n (-xiv...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Re: Can men get yeast infections?\\n\\nMy (then)...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "      <td>(error)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Re: INFO: Colonics and Purification?\\n\\nIn art...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "      <td>alt.health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Re: Space Marketing would be wonderfull.\\n\\n&gt;&gt;...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>sci.astro.amateur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Re: HST Servicing Mission Scheduled for 11 Day...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-756ec0d1-6b95-43bf-975b-81060f630a85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-756ec0d1-6b95-43bf-975b-81060f630a85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-756ec0d1-6b95-43bf-975b-81060f630a85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a0919ca9-ee8c-48b3-9971-3d30ea89bcf7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0919ca9-ee8c-48b3-9971-3d30ea89bcf7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a0919ca9-ee8c-48b3-9971-3d30ea89bcf7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_09cc51f8-f144-4d11-a4b9-b90c860b37d0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_baseline_eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09cc51f8-f144-4d11-a4b9-b90c860b37d0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_baseline_eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_baseline_eval",
              "summary": "{\n  \"name\": \"df_baseline_eval\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Re: Changing brake fluid..is it necessary..\\n\\nIn article <>  writes:\\n\\n\\n> Hi.\\n>  I've been seeing all these articles about changing\\n> brake fluid and I am wondering if this is really necessary.\\n> I have an 86 Toyota Corolla SR5, with 94000 and I am in the\\n\\nOnly if you want to stop. Seriously though, every 2 years you should\\nhave this done. Brake fluid absorbs water over time, the water becomes\\nsteam when the fluid gets hot, and steam compresses. You'll also have\\nbetter luck with the longevity of master cylinder, calipers and brake\\nlines.\\n\\nJeff Goss\\n\",\n          \"Re: Dirty Diesels?\\n\\n  writes:\\n> I heard the diesels are considered cleaner-burning than\\n> gas engines because the emit less of: Carbon Monoxide,\\n> Hydrocarbons, and Oxides of Nitrogen.  (CO, HC, NOX).\\n> \\n> But they can put out a lot of particulate matter.  I heard\\n> something about legislation being discussed to \\\"clean up\\n> diesel emissions\\\".  Is there anything in the works to\\n> install \\\"scrubbers\\\" for diesels?  How about the feasibility\\n> of installing them on trucks and cars?  Would it be any\\n> different than a catylitic converter?  I'd assume easier,\\n> since we're removing particulate matter instead of converting\\n> gasses.  Let's hear people's opinions...\\n> \\n\\nVW and Mercedes have tinkered with particulate traps.  Also, VW\\nuses a kind of turbocharger on their Jetta ECOdiesel that helps\\nreduce particulates as well, although I don't know the\\nmechanics of it.\\n\\nMany diesel cars,busses, and trucks in Europe are now being\\nequipped with catalysts and traps in an effort to clean up\\ndiesel emissions, already well below legal limits anyway.\\n\\nIt's a shame GM had to soil the diesel's reputation in\\npassenger cars and prevent further resource devotion to\\nresearch into making this outstandingly efficient engine even\\nfurther ahead of gas engines in emissions.\\n\\nerik\\n\",\n          \"Re: USA McWeekly Stats\\n <>\\n <>\\n\\nIn article <>, \\n(Greg Spira) says:\\n>\\n><> writes:\\n>\\n>>In article <>, \\n>>(John Franjione) says:\\n>>>\\n>>>Also, I have the impression from reading this group and Bill James\\n>>>that Elias is a bunch of money-grubbing jerks whose mission is to\\n>>>charge as much as they can for baseball statistical info\\n>>>\\n>\\n>>and bill james is not? yeah.  sure.  do you own \\\"the bill james players\\n>>rating book\\\"?\\n>\\n>Uh, Bill James doesn't sell statistics.  He sells books with statistics,\\n>but he is not in the business of providing stats like Elias, STATS,\\n>Howe, Baseball workshop etc. are.\\n>\\n>Greg\\n\\nfunny, it seems to me that the stats major league and minor league handbooks,\\nwhich are nothing BUT collections of statistics, are authored by \\\"bill james\\nand stats inc. (and howe, for the minor league handbook)\\\".\\n\\nand i am not sure how the 1993 bill james player ratings book qualifies\\nas a \\\"book with statistics\\\", while the elias analyst is a \\\"statistics book\\\".\\nthe analyst contains more stats, sure, but it also contains more dialogue.\\n\\nfinally, the point was not about the word \\\"statistics\\\".  it was about\\n\\\"money-grubbing\\\".  i don't see how anyone who has looked at the bill\\njames player ratings book cannot consider him money-grubbing.\\n\\nbob vesterman.\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 7,\n        \"max\": 14,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          12,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"rec.motorcycles\",\n          \"sci.electronics\",\n          \"rec.autos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"sci.astro.amateur\",\n          \"comp.os.ms-windows.misc\",\n          \"rec.autos.toyota\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune a custom model\n",
        "\n",
        "In this example you'll use tuning to create a model that requires no prompting or system instructions and outputs succinct text from the classes you provide in the training data.\n",
        "\n",
        "The data contains both input text (the processed posts) and output text (the category, or newsgroup), that you can use to start tuning a model.\n",
        "\n",
        "When calling `tune()`, you can specify model tuning hyperparameters too:\n",
        " - `epoch_count`: defines how many times to loop through the data,\n",
        " - `batch_size`: defines how many rows to process in a single step, and\n",
        " - `learning_rate`: defines the scaling factor for updating model weights at each step.\n",
        "\n",
        "You can also choose to omit them and use the defaults. [Learn more](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) about these parameters and how they work. For this example these parameters were selected by running some tuning jobs and selecting parameters that converged efficiently.\n",
        "\n",
        "This example will start a new tuning job, but only if one does not already exist. This allows you to leave this codelab and come back later - re-running this step will find your last model."
      ],
      "metadata": {
        "id": "Ok7ugrLzcghX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "import random\n",
        "\n",
        "\n",
        "# Convert the data frame into a dataset suitable for tuning.\n",
        "input_data = {'examples':\n",
        "    df_train[['Text', 'Class Name']]\n",
        "      .rename(columns={'Text': 'textInput', 'Class Name': 'output'})\n",
        "      .to_dict(orient='records')\n",
        " }\n",
        "\n",
        "# If you are re-running this lab, add your model_id here.\n",
        "model_id = None\n",
        "\n",
        "# Or try and find a recent tuning job.\n",
        "if not model_id:\n",
        "  queued_model = None\n",
        "  # Newest models first.\n",
        "  for m in reversed(client.tunings.list()):\n",
        "    # Only look at newsgroup classification models.\n",
        "    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n",
        "      # If there is a completed model, use the first (newest) one.\n",
        "      if m.state.name == 'JOB_STATE_SUCCEEDED':\n",
        "        model_id = m.name\n",
        "        print('Found existing tuned model to reuse.')\n",
        "        break\n",
        "\n",
        "      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n",
        "        # If there's a model still queued, remember the most recent one.\n",
        "        queued_model = m.name\n",
        "  else:\n",
        "    if queued_model:\n",
        "      model_id = queued_model\n",
        "      print('Found queued model, still waiting.')\n",
        "\n",
        "\n",
        "# Upload the training data and queue the tuning job.\n",
        "if not model_id:\n",
        "    tuning_op = client.tunings.tune(\n",
        "        base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
        "        training_dataset=input_data,\n",
        "        config=types.CreateTuningJobConfig(\n",
        "            tuned_model_display_name=\"Newsgroup classification model\",\n",
        "            batch_size=16,\n",
        "            epoch_count=2,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    print(tuning_op.state)\n",
        "    model_id = tuning_op.name\n",
        "\n",
        "print(model_id)"
      ],
      "metadata": {
        "id": "pWOZlspfY8dV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T07:55:53.141652Z",
          "iopub.execute_input": "2025-04-02T07:55:53.142071Z",
          "iopub.status.idle": "2025-04-02T07:55:55.004654Z",
          "shell.execute_reply.started": "2025-04-02T07:55:53.142034Z",
          "shell.execute_reply": "2025-04-02T07:55:55.003495Z"
        },
        "outputId": "d074e82a-eb5e-4171-cd83-18bb0d46467a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found queued model, still waiting.\n",
            "tunedModels/newsgroup-classification-model-2y3t57kwj\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has created a tuning job that will run in the background. To inspect the progress of the tuning job, run this cell to plot the current status and loss curve. Once the status reaches `ACTIVE`, tuning is complete and the model is ready to use.\n",
        "\n",
        "Tuning jobs are queued, so it may look like no training steps have been taken initially but it will progress. Tuning can take anywhere from a few minutes to multiple hours, depending on factors like your dataset size and how busy the tuning infrastrature is. Why not treat yourself to a nice cup of tea while you wait, or come and say \"Hi!\" in the group [Discord](https://discord.com/invite/kaggle).\n",
        "\n",
        "It is safe to stop this cell at any point. It will not stop the tuning job.\n",
        "\n",
        "**IMPORTANT**: Due to the high volume of users doing this course, tuning jobs may be queued for many hours. Take a note of your tuned model ID above (`tunedModels/...`) so you can come back to it tomorrow. In the meantime, check out the [Search grounding](https://www.kaggle.com/code/markishere/day-4-google-search-grounding/) codelab. If you want to try tuning a local LLM, check out [the fine-tuning guides for tuning a Gemma model](https://ai.google.dev/gemma/docs/tune)."
      ],
      "metadata": {
        "id": "NQ3YZ2MBubCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "\n",
        "MAX_WAIT = datetime.timedelta(minutes=10)\n",
        "\n",
        "while not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n",
        "\n",
        "    print(tuned_model.state)\n",
        "    time.sleep(60)\n",
        "\n",
        "    # Don't wait too long. Use a public model if this is going to take a while.\n",
        "    if datetime.datetime.now(datetime.timezone.utc) - tuned_model.create_time > MAX_WAIT:\n",
        "        print(\"Taking a shortcut, using a previously prepared model.\")\n",
        "        model_id = \"tunedModels/newsgroup-classification-model-ltenbi1b\"\n",
        "        tuned_model = client.tunings.get(name=model_id)\n",
        "        break\n",
        "\n",
        "\n",
        "print(f\"Done! The model state is: {tuned_model.state.name}\")\n",
        "\n",
        "if not tuned_model.has_succeeded and tuned_model.error:\n",
        "    print(\"Error:\", tuned_model.error)"
      ],
      "metadata": {
        "id": "c4ef5f13692d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T08:11:13.878313Z",
          "iopub.execute_input": "2025-04-02T08:11:13.878725Z",
          "iopub.status.idle": "2025-04-02T08:11:15.417549Z",
          "shell.execute_reply.started": "2025-04-02T08:11:13.878693Z",
          "shell.execute_reply": "2025-04-02T08:11:15.416441Z"
        },
        "outputId": "fe781def-1548-4101-b0a1-2772d14607f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! The model state is: JOB_STATE_SUCCEEDED\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the new model\n",
        "\n",
        "Now that you have a tuned model, try it out with custom data. You use the same API as a normal Gemini API interaction, but you specify your new model as the model name, which will start with `tunedModels/`."
      ],
      "metadata": {
        "id": "9-qiIdK4u80z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"\"\"\n",
        "First-timer looking to get out of here.\n",
        "\n",
        "Hi, I'm writing about my interest in travelling to the outer limits!\n",
        "\n",
        "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
        "\n",
        "Let me know how to do that please.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_id, contents=new_text)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "hyO2-MXLvM6a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T08:11:24.915979Z",
          "iopub.execute_input": "2025-04-02T08:11:24.91659Z",
          "iopub.status.idle": "2025-04-02T08:11:27.566345Z",
          "shell.execute_reply.started": "2025-04-02T08:11:24.91654Z",
          "shell.execute_reply": "2025-04-02T08:11:27.564861Z"
        },
        "outputId": "0e0d5fa2-501c-42c8-df82-4db92e99a081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rec.motorcycles\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "You can see that the model outputs labels that correspond to those in the training data, and without any system instructions or prompting, which is already a great improvement. Now see how well it performs on the test set.\n",
        "\n",
        "Note that there is no parallelism in this example; classifying the test sub-set will take a few minutes."
      ],
      "metadata": {
        "id": "xajLek9DySH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@retry.Retry(predicate=is_retriable)\n",
        "def classify_text(text: str) -> str:\n",
        "    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=model_id, contents=text)\n",
        "    rc = response.candidates[0]\n",
        "\n",
        "    # Any errors, filters, recitation, etc we can mark as a general error\n",
        "    if rc.finish_reason.name != \"STOP\":\n",
        "        return \"(error)\"\n",
        "    else:\n",
        "        return rc.content.parts[0].text\n",
        "\n",
        "\n",
        "# The sampling here is just to minimise your quota usage. If you can, you should\n",
        "# evaluate the whole test set with `df_model_eval = df_test.copy()`.\n",
        "df_model_eval = sample_data(df_test, 4, '.*')\n",
        "\n",
        "df_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n",
        "\n",
        "accuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "6T2Y3ZApvbMw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T08:11:29.712728Z",
          "iopub.execute_input": "2025-04-02T08:11:29.713129Z",
          "iopub.status.idle": "2025-04-02T08:14:02.348228Z",
          "shell.execute_reply.started": "2025-04-02T08:11:29.713082Z",
          "shell.execute_reply": "2025-04-02T08:14:02.347128Z"
        },
        "outputId": "bec555a5-4f02-4fe5-a10c-5f51b3fd1f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "cb74809972ee4c01b1f87e24e5bcf545",
            "2ba65669016a4f829d6e09ae17a95e38"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb74809972ee4c01b1f87e24e5bcf545"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.12%\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare token usage\n",
        "\n",
        "AI Studio and the Gemini API provide model tuning at no cost, however normal limits and charges apply for *use* of a tuned model.\n",
        "\n",
        "The size of the input prompt and other generation config like system instructions, as well as the number of generated output tokens, all contribute to the overall cost of a request."
      ],
      "metadata": {
        "id": "gqzpObPiyDX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the *input* cost of the baseline model with system instructions.\n",
        "sysint_tokens = client.models.count_tokens(\n",
        "    model='gemini-1.5-flash-001', contents=[system_instruct, sample_row]\n",
        ").total_tokens\n",
        "print(f'System instructed baseline model: {sysint_tokens} (input)')\n",
        "\n",
        "# Calculate the input cost of the tuned model.\n",
        "tuned_tokens = client.models.count_tokens(model=tuned_model.base_model, contents=sample_row).total_tokens\n",
        "print(f'Tuned model: {tuned_tokens} (input)')\n",
        "\n",
        "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
        "print(f'Token savings: {savings:.2%}')  # Note that this is only n=1."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T08:14:02.35288Z",
          "iopub.execute_input": "2025-04-02T08:14:02.353306Z",
          "iopub.status.idle": "2025-04-02T08:14:02.612742Z",
          "shell.execute_reply.started": "2025-04-02T08:14:02.353257Z",
          "shell.execute_reply": "2025-04-02T08:14:02.611517Z"
        },
        "id": "TZs0ZRsxyDX9",
        "outputId": "714c0293-2e64-4de8-df3b-404f0d036bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System instructed baseline model: 172 (input)\n",
            "Tuned model: 136 (input)\n",
            "Token savings: 26.47%\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "The earlier verbose model also produced more output tokens than needed for this task."
      ],
      "metadata": {
        "id": "OBTAEGZbyDX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_token_output = baseline_response.usage_metadata.candidates_token_count\n",
        "print('Baseline (verbose) output tokens:', baseline_token_output)\n",
        "\n",
        "tuned_model_output = client.models.generate_content(\n",
        "    model=model_id, contents=sample_row)\n",
        "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
        "print('Tuned output tokens:', tuned_tokens_output)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T08:14:02.614741Z",
          "iopub.execute_input": "2025-04-02T08:14:02.615096Z",
          "iopub.status.idle": "2025-04-02T08:14:03.532486Z",
          "shell.execute_reply.started": "2025-04-02T08:14:02.615061Z",
          "shell.execute_reply": "2025-04-02T08:14:03.531188Z"
        },
        "id": "PzFmDIXfyDX9",
        "outputId": "73246276-044c-409c-84ef-28d13b8be1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (verbose) output tokens: 257\n",
            "Tuned output tokens: 3\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "Now that you have tuned a classification model, try some other tasks, like tuning a model to respond with a specific tone or style using hand-written examples (or even generated examples!). Kaggle hosts [a number of datasets](https://www.kaggle.com/datasets) you can try out.\n",
        "\n",
        "Learn about [when supervised fine-tuning is most effective](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n",
        "\n",
        "And check out the [fine-tuning tutorial](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) for another example that shows a tuned model extending beyond the training data to new, unseen inputs.\n",
        "\n",
        "*- [Mark McD](https://linktr.ee/markmcd)*"
      ],
      "metadata": {
        "id": "6c1204a5d0ab"
      }
    }
  ]
}